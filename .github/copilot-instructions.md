# Copilot Instructions for Aiye

Aiye √© uma plataforma RAG (Retrieval-Augmented Generation) para perguntas sobre Umbanda que combina embeddings vetoriais, busca sem√¢ntica e Google Gemini 2.5 Flash.

## üèóÔ∏è Arquitetura

**Frontend (React 18.2 + TypeScript 5.0 + Vite 5.0 + Tailwind 3.3)**
- Deployed em Vercel
- Cliente HTTP via Axios (`src/api.ts`)
- Componentes: ChatBox, AnswerCard, SourceList
- Health check do backend no mount

**Backend (FastAPI 0.115.0 + Python 3.11 + Docker)**
- Deployed em Hugging Face Spaces (porta 7860)
- 3 endpoints: `/healthz`, `/warmup`, `/ask`
- RAG pipeline: Search (FAISS + BM25 h√≠brido) ‚Üí Re-ranking ‚Üí Gemini
- Local-first: Respostas APENAS baseadas em PDFs indexados

**Storage (Git LFS)**
- `backend/data/pdfs/`: 7 PDFs (~20MB)
- `backend/data/index/index.faiss`: √çndice FAISS com 11.799 vetores
- `backend/data/index/metadata.json`: Metadados dos chunks (22MB)

## üéØ Regra de Ouro do RAG

‚úÖ **Respostas DEVEM ser baseadas APENAS no acervo de PDFs**
- Gemini √© "tradutor de contextos" ‚Üí reformula linguisticamente contextos recuperados
- **PROIBIDO**: Adicionar informa√ß√µes, deduzir, supor, inventar
- **Quando n√£o h√° info**: Retornar "N√£o encontrei essa informa√ß√£o no acervo"

Ver coment√°rio de filosofia em `backend/rag.py` linhas 1-40.

## üìã Stack & Modelos

| Componente | Vers√£o |
|-----------|--------|
| **Embedding** | sentence-transformers/all-MiniLM-L6-v2 (384 dimens√µes) |
| **LLM** | Google Gemini 2.5 Flash (google-generativeai 0.8.3) |
| **Vector DB** | FAISS 1.13.0 (CPU) |
| **FastAPI** | 0.115.0 + Uvicorn 0.30.0 |
| **React** | 18.2.0 + React Router 7.9.6 |
| **Busca H√≠brida** | FAISS (dense) + BM25 (sparse) |

## üîë Configura√ß√µes Cr√≠ticas

Arquivo: `backend/settings.py`

```python
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
TOP_K = 8                    # N√∫mero de chunks recuperados
MIN_SIM = 0.30              # Filtro m√≠nimo de similaridade
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
```

Carregam de `.env` na raiz do projeto (via python-dotenv).

## üîÑ Fluxos Cr√≠ticos

### 1. Ingest√£o de PDFs
```bash
# Coloca PDFs em backend/data/pdfs/
python backend/ingest.py
```
- Extrai texto com PyMuPDF (fitz)
- Chunking sem√¢ntico respeitando senten√ßas/par√°grafos
- Gera embeddings + FAISS + metadata.json
- Salva em Git LFS

### 2. Query do Usu√°rio (POST /ask)
```
Pergunta ‚Üí Embedar ‚Üí Busca H√≠brida (FAISS + BM25) ‚Üí Re-ranking ‚Üí 
Gemini (reformula√ß√£o) ‚Üí Agrega√ß√£o de fontes ‚Üí Resposta
```

Implementado em `backend/rag.py:search()` e `generate_answer()`.

### 3. Deploy em HF Spaces
```dockerfile
# Docker autom√°tico, executa:
python backend/init_index.py  # Valida √≠ndices
uvicorn backend.app:app --port 7860
```

## üìÅ Estrutura de Arquivos Essenciais

| Arquivo | Prop√≥sito |
|---------|-----------|
| `backend/rag.py` | Pipeline RAG completo (564 linhas, comentado) |
| `backend/main.py` | Endpoints FastAPI + CORS |
| `backend/ingest.py` | Script CLI de ingest√£o |
| `backend/models.py` | Valida√ß√£o Pydantic (AskRequest, AskResponse) |
| `backend/settings.py` | Carregamento de configura√ß√µes .env |
| `frontend/src/api.ts` | Cliente HTTP (interface AskResponse) |
| `frontend/src/App.tsx` | Componente raiz + gerenciamento de chat |
| `.env.example` | Template de vari√°veis (copiar para .env) |

## üõ†Ô∏è Workflows de Desenvolvimento

### Local Backend
```bash
# 1. Setup
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -r backend/requirements.txt

# 2. Criar .env (copiar de .env.example)
# 3. Ingerir PDFs (se necess√°rio)
python backend/ingest.py

# 4. Rodar servidor
uvicorn backend.main:app --reload --port 8000
# Acesse: http://localhost:8000/docs (Swagger)
```

### Local Frontend
```bash
cd frontend
npm install
npm run dev  # Acesse http://localhost:5173
# Configura VITE_API_BASE=http://localhost:8000
```

### Testar Integra√ß√£o
```bash
python test_api.py  # Testa endpoints b√°sicos
python test_db_connection.py  # Valida √≠ndices
```

### Build & Deploy
- **Frontend**: Vercel automaticamente ao push em main
- **Backend**: GitHub Actions ‚Üí HF Spaces (Dockerfile)

## üîå Integra√ß√µes Externas

1. **Google Gemini 2.5 Flash**
   - Chave em `GOOGLE_API_KEY`
   - Importado em `backend/rag.py:generate_answer()`
   - **Prompt cr√≠tico**: "Reformule usando APENAS os contextos. N√£o invente informa√ß√£o."

2. **Git LFS** para PDFs e √≠ndices
   - Configurado em `.gitattributes`
   - Essencial para deploy em HF Spaces

3. **CORS**: Whitelist expl√≠cita em `backend/main.py`
   - Localhost (dev): `http://localhost:5173`, `http://localhost:3000`
   - Produ√ß√£o: `https://aiye-chat.vercel.app`

## üé® Padr√µes do Projeto

### Backend
- **Logging**: `print()` com prefixos (‚úì, ‚úó, ‚Ñπ, üîç, üìÑ, etc.)
- **Valida√ß√£o**: Pydantic models, min_length/max_length expl√≠citos
- **Async**: FastAPI async endpoints, espera de I/O
- **Estrutura**: Modular, separa√ß√£o clara (rag.py, models.py, settings.py)

### Frontend
- **State**: React hooks (`useState`, `useEffect`)
- **HTTP**: Async/await com try-catch em `api.ts`
- **CSS**: Tailwind com classes customizadas (`.umbanda-primary`, `.umbanda-secondary`)
- **UI/UX**: Loading states, error messages, health check visual

### Ambos
- **Environment**: `.env` para secrets e configura√ß√£o
- **CI/CD**: Git LFS para assets, Dockerfile otimizado
- **Documenta√ß√£o**: Markdown em `DEVELOPMENT.md`, `PROJECT_SUMMARY.md`

## ‚ö° Tarefas Comuns

### Adicionar novo endpoint
```python
# backend/main.py
@app.post("/novo")
async def novo(request: SomeRequest) -> SomeResponse:
    # Implementar e adicionar modelo em models.py
```

### Ajustar RAG parameters
```python
# .env
TOP_K=10              # Aumentar chunks
MIN_SIM=0.25          # Lowering threshold
EMBEDDING_MODEL=...   # Mudar modelo (cuidado: dimensionalidade!)
```

### Mudar tamanho de chunks
```python
# backend/rag.py chunk_text_semantic()
chunk_size=1500       # Aumentado de 1200
overlap=200           # Aumentado de 150
```

### Debug de respostas
- Checar `metadata.json` para coverage de documentos
- Usar `/docs` para testar manualmente POST /ask
- Verificar GOOGLE_API_KEY se Gemini falhar
- Logs em `backend/rag.py` indicam search score e re-ranking

## ‚ùå Evitar

- ‚ùå Hardcoding de URLs (usar `.env`)
- ‚ùå Responder sem fontes (sempre incluir Source objects)
- ‚ùå Modificar √≠ndices manualmente (sempre via `ingest.py`)
- ‚ùå CORS aberto (`*`) em produ√ß√£o
- ‚ùå Conhecimento pr√©vio do Gemini (sempre usar contextos recuperados)

## üìö Refer√™ncias R√°pidas

- **RAG Philosophy**: `backend/rag.py` linhas 1-40
- **API Contracts**: `backend/models.py` (Pydantic schemas)
- **Config Loading**: `backend/settings.py`
- **Frontend API Client**: `frontend/src/api.ts`
- **Full Architecture**: `PROJECT_SUMMARY.md`
- **Setup Local**: `QUICKSTART.md`
