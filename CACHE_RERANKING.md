# Cache e Re-ranking - Melhorias RAG

## Vis√£o Geral

Este documento descreve as melhorias implementadas no sistema RAG (Retrieval-Augmented Generation) para otimizar **desempenho** (cache) e **qualidade** (re-ranking) das respostas.

## 1. Cache de Respostas (LRU)

### Objetivo
Reduzir lat√™ncia e custos de API ao armazenar respostas para perguntas frequentes.

### Implementa√ß√£o
**Arquivo**: `backend/cache.py`

**Classe Principal**: `ResponseCache`

**Caracter√≠sticas**:
- **Algoritmo**: LRU (Least Recently Used) - Remove respostas menos usadas quando atinge capacidade m√°xima
- **Capacidade**: 100 respostas (configur√°vel via `max_size`)
- **Chave**: MD5 hash da pergunta normalizada (lowercase, sem pontua√ß√£o, espa√ßos normalizados)
- **Armazenamento**: Em mem√≥ria (dict Python)
- **Persist√™ncia**: N√£o persistente (reinicia com cada deploy)

**Normaliza√ß√£o de Perguntas**:
```python
"O que √© Umbanda?" ‚Üí "o que e umbanda"
"O QUE √â UMBANDA?!!" ‚Üí "o que e umbanda"
```
Isso permite que varia√ß√µes da mesma pergunta compartilhem o mesmo cache.

**M√©todos**:
- `get(question)`: Retorna `{'answer': str, 'contexts': list, 'original_question': str}` ou `None`
- `set(question, answer, contexts)`: Armazena resposta, evita duplicatas se existir
- `stats()`: Retorna `{'size': int, 'max_size': int, 'usage_percent': float}`
- `clear()`: Limpa todo o cache

**Singleton**:
```python
from backend.cache import get_response_cache
cache = get_response_cache()  # Sempre retorna a mesma inst√¢ncia global
```

### Logs
```
Cache HIT: "o que e umbanda" (MD5: a1b2c3...)
Cache MISS: "quem sao os orixas" (MD5: d4e5f6...)
‚úì Resposta armazenada no cache (1/100)
‚ö†Ô∏è Cache cheio! Removendo entrada menos usada: "pergunta antiga"
```

### Endpoint de Monitoramento
**GET** `/cache/stats`

**Resposta**:
```json
{
  "size": 42,
  "max_size": 100,
  "usage_percent": 42.0
}
```

### Configura√ß√£o
Para alterar o tamanho do cache, edite `backend/rag.py`:
```python
cache = get_response_cache(max_size=200)  # Aumenta para 200 respostas
```

## 2. Re-ranking Multi-Signal

### Objetivo
Melhorar a relev√¢ncia dos documentos recuperados al√©m da similaridade sem√¢ntica pura do FAISS.

### Implementa√ß√£o
**Arquivo**: `backend/reranker.py`

**Fun√ß√£o Principal**: `rerank_results(query, results)`

**Sinais de Relev√¢ncia** (4 componentes):

#### 1. Similaridade Sem√¢ntica (50%)
- Score original do FAISS (produto interno normalizado)
- Base: embedding vetorial da pergunta vs contextos

#### 2. Sobreposi√ß√£o de Keywords (25%)
- Remove stopwords em portugu√™s (de, para, com, etc.)
- Conta palavras da pergunta que aparecem no conte√∫do
- F√≥rmula: `overlap_count / max(query_words, content_words)`

#### 3. Posi√ß√£o Original (10%)
- Privilegia documentos que FAISS ranqueou no topo
- F√≥rmula: `1.0 / (1 + rank * 0.5)` (decaimento exponencial)

#### 4. Qualidade do Conte√∫do (15%)
Heur√≠sticas para textos bem estruturados:
- **Comprimento**: 300-1500 caracteres (ideal para contexto)
  - 0.4 pontos se ideal
  - 0.2 pontos se 150-300 ou 1500-2000
  - 0.0 se muito curto/longo
- **Estrutura**: N√∫mero de senten√ßas
  - 0.3 pontos se 3+ senten√ßas
  - 0.15 pontos se 1-2 senten√ßas
- **Densidade**: Caracteres por palavra (m√©dia portugu√™s = 5)
  - 0.3 pontos se 4-8 chars/palavra
  - 0.0 caso contr√°rio

### F√≥rmula Final
```python
final_score = (
    semantic * 0.50 +
    keyword_overlap * 0.25 +
    position * 0.10 +
    content_quality * 0.15
)
```

### Logs Detalhados
```
üîÑ Re-ranking 8 resultados para query: "o que √© umbanda"

Resultado 1 (original rank 0):
  Semantic: 0.8500
  Keywords: 0.6667 (4/6 palavras)
  Position: 1.0000 (rank 0)
  Quality: 0.8500 (length=0.4, structure=0.3, density=0.15)
  FINAL: 0.7958

[Scores originais]
  0.8500 ‚Üí 0.7958 ‚úì
  0.8200 ‚Üí 0.7123 ‚Üì
  ...

Re-ranking completo! Top resultado: UMBANDA: religi√£o do Brasil (pp. 12-14)
```

### Metadados Adicionados
Cada resultado retornado inclui:
```python
{
  "content": "...",
  "title": "...",
  "page_start": 12,
  "page_end": 14,
  "score": 0.85,  # Score sem√¢ntico original
  "final_score": 0.7958,  # Score ap√≥s re-ranking
  "rerank_details": {
    "semantic_similarity": 0.85,
    "keyword_overlap": 0.6667,
    "position_score": 1.0,
    "content_quality": 0.85
  }
}
```

### Ativa√ß√£o/Desativa√ß√£o
**Padr√£o**: Re-ranking ativado automaticamente

**Para desativar**:
```python
# Em backend/rag.py, fun√ß√£o ask_with_cache()
answer, contexts = ask_with_cache(
    question=question,
    use_reranking=False  # Desativa re-ranking
)
```

## 3. Integra√ß√£o Completa

### Fluxo de Requisi√ß√£o
```
POST /ask {"question": "o que √© umbanda?"}
  ‚Üì
1. ask_with_cache()
  ‚Üì
2. cache.get("o que e umbanda")  # Normaliza e busca
  ‚Üì
3a. [CACHE HIT] ‚Üí Retorna resposta instantaneamente ‚úì
  ‚Üì
3b. [CACHE MISS] ‚Üí search() com re-ranking
  ‚Üì
4. FAISS: Busca top-8 documentos (semantic similarity)
  ‚Üì
5. rerank_results(): Reordena com 4 sinais
  ‚Üì
6. generate_answer(): Gemini sintetiza resposta
  ‚Üì
7. cache.set(): Armazena para pr√≥xima vez
  ‚Üì
8. Retorna resposta + fontes + metadata
```

### Endpoints Afetados
- **POST** `/ask` - Usa cache + re-ranking
- **POST** `/ask-raw` - Usa cache + re-ranking
- **GET** `/cache/stats` - Estat√≠sticas do cache (novo)

## 4. Testes e Valida√ß√£o

### Testar Cache
```bash
# 1¬™ requisi√ß√£o (CACHE MISS)
curl -X POST https://dev-mateus-backend-aiye.hf.space/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "o que √© umbanda?"}'

# Verifique logs: "Cache MISS: o que e umbanda"

# 2¬™ requisi√ß√£o (CACHE HIT - deve ser instant√¢nea)
curl -X POST https://dev-mateus-backend-aiye.hf.space/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "O QUE √â UMBANDA?!!"}'  # Varia√ß√£o normalizada

# Verifique logs: "Cache HIT: o que e umbanda"
```

### Verificar Estat√≠sticas
```bash
curl https://dev-mateus-backend-aiye.hf.space/cache/stats
```

### Testar Re-ranking
Compare scores nos logs:
```
[Scores originais]  # Antes do re-ranking
  0.8500 ‚Üí 0.7958 ‚úì  # Este melhorou (mais keywords)
  0.8200 ‚Üí 0.7123 ‚Üì  # Este piorou (menos keywords)
```

Documentos com mais keywords da pergunta sobem no ranking.

## 5. Impacto Esperado

### Cache
- **Lat√™ncia**: ~2000ms ‚Üí ~50ms para perguntas repetidas
- **Custos**: Reduz chamadas √† API Gemini
- **Hit Rate Esperado**: 20-40% (depende de perguntas repetidas)

### Re-ranking
- **Qualidade**: Melhora relev√¢ncia em 10-30%
- **Precis√£o**: Documentos com keywords corretas sobem
- **Recall**: Mant√©m cobertura (n√£o remove documentos)

## 6. Limita√ß√µes e Pr√≥ximos Passos

### Limita√ß√µes Atuais
- Cache n√£o persiste entre deploys (em mem√≥ria)
- Stopwords apenas em portugu√™s
- Heur√≠sticas de qualidade simples

### Melhorias Futuras
- [ ] Cache persistente (Redis/Memcached)
- [ ] Re-ranking com modelo cross-encoder (mais lento, mais preciso)
- [ ] Cache TTL (expira√ß√£o por tempo)
- [ ] M√©tricas de hit rate no admin dashboard
- [ ] A/B testing cache on/off

## 7. Troubleshooting

### Cache n√£o est√° funcionando
```python
# Verifique se est√° ativado
answer, contexts = ask_with_cache(use_cache=True)

# Verifique logs para "Cache HIT/MISS"
# Se n√£o aparecer, verifique imports em app.py
```

### Re-ranking piora resultados
```python
# Desative temporariamente
answer, contexts = ask_with_cache(use_reranking=False)

# Ajuste pesos em backend/reranker.py linha ~140:
final_score = (
    semantic * 0.70 +  # Aumenta peso sem√¢ntico
    keyword * 0.20 +   # Reduz keywords
    position * 0.05 +
    quality * 0.05
)
```

### Cache cheio muito r√°pido
```python
# Aumente capacidade em backend/rag.py
cache = get_response_cache(max_size=500)
```

---

**Autor**: Implementado em 2024  
**Vers√£o**: 1.0  
**Arquivos**: `backend/cache.py`, `backend/reranker.py`, `backend/rag.py`, `backend/app.py`
